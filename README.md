📁 Project Overview
In this module, I worked with a raw CSV file containing carbon emissions data. The goal was to clean and preprocess this data to make it suitable for downstream analysis. Key tasks included:
- Handling missing values
- Standardizing column formats
- Removing duplicates
- Renaming columns for clarity
- Converting data types where needed
🛠️ Tools & Libraries
- Python 3.x
- Jupyter Notebook
- pandas
- numpy
- matplotlib (optional for quick visual checks)
🧹 Data Cleaning Steps
- Exploration: Loaded the dataset and examined basic statistics and structure.
- Missing Values: Identified null entries and used techniques like imputation or row removal.
- Data Types: Ensured consistency across all columns by converting to appropriate types.
- Duplicates: Removed redundant rows.
- Renaming and Reindexing: Improved column names and index formatting for clarity.
📊 Output
The final cleaned dataset is ready for further statistical analysis, visualization, or machine learning modeling in upcoming weeks.
📌 Directory Structure
Carbon_Emissions_Week-1/
│
├── Carbon_Emissions_Cleaning.ipynb
├── raw_data.csv
├── cleaned_data.csv
└── README.md


🚀 Getting Started
To run the notebook locally:
- Clone the repository.
- Install the required libraries:
pip install pandas numpy matplotlib
- Open the notebook using Jupyter:
jupyter notebook data_preparation_week_1.ipynb




